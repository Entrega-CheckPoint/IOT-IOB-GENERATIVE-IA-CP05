{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "565bbf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers, regularizers, Input\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4f05c3",
   "metadata": {},
   "source": [
    "#### EXERCÍCIO 1 – CLASSIFICAÇÃO MULTICLASSE\n",
    "\n",
    "Dataset: Wine Dataset (UCI)\n",
    "\n",
    "1. Treinar uma rede neural em Keras para classificar vinhos em 3 classes.\n",
    "\n",
    "- Configuração mínima: 2 camadas ocultas com 32 neurônios cada, função de ativação ReLU.\n",
    "- Camada de saída com 3 neurônios, função de ativação Softmax.\n",
    "- Função de perda: categorical_crossentropy.\n",
    "- Otimizador: Adam.\n",
    "\n",
    "2. Comparar os resultados com um modelo do scikit-learn (RandomForestClassifier ou\n",
    "   LogisticRegression).\n",
    "3. Registrar métricas de acurácia e discutir qual modelo teve melhor desempenho.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "81bbfe8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alcohol',\n",
       " 'Malic acid',\n",
       " 'Ash',\n",
       " 'Alcalinity of ash',\n",
       " 'Magnesium',\n",
       " 'Total phenols',\n",
       " 'Flavanoids',\n",
       " 'Nonflavanoid phenols',\n",
       " 'Proanthocyanins',\n",
       " 'Color intensity',\n",
       " 'Hue',\n",
       " 'OD280/OD315 of diluted wines',\n",
       " 'Proline']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista = [\n",
    "    \" Alcohol\",\n",
    "    \" Malic acid\",\n",
    "    \" Ash\",\n",
    "    \" Alcalinity of ash  \",\n",
    "    \" Magnesium\",\n",
    "    \" Total phenols\",\n",
    "    \" Flavanoids\",\n",
    "    \" Nonflavanoid phenols\",\n",
    "    \" Proanthocyanins\",\n",
    "    \"Color intensity\",\n",
    "    \"Hue\",\n",
    "    \"OD280/OD315 of diluted wines\",\n",
    "    \"Proline            \",\n",
    "]\n",
    "\n",
    "lista = [x.strip() for x in lista]\n",
    "lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "171a0f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "0      1    14.23        1.71  2.43               15.6        127   \n",
       "1      1    13.20        1.78  2.14               11.2        100   \n",
       "2      1    13.16        2.36  2.67               18.6        101   \n",
       "3      1    14.37        1.95  2.50               16.8        113   \n",
       "4      1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "0             5.64  1.04                          3.92     1065  \n",
       "1             4.38  1.05                          3.40     1050  \n",
       "2             5.68  1.03                          3.17     1185  \n",
       "3             7.80  0.86                          3.45     1480  \n",
       "4             4.32  1.04                          2.93      735  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input de dados\n",
    "\n",
    "COLUMN_NAMES = [\n",
    "    \"Class\",\n",
    "    \"Alcohol\",\n",
    "    \"Malic acid\",\n",
    "    \"Ash\",\n",
    "    \"Alcalinity of ash\",\n",
    "    \"Magnesium\",\n",
    "    \"Total phenols\",\n",
    "    \"Flavanoids\",\n",
    "    \"Nonflavanoid phenols\",\n",
    "    \"Proanthocyanins\",\n",
    "    \"Color intensity\",\n",
    "    \"Hue\",\n",
    "    \"OD280/OD315 of diluted wines\",\n",
    "    \"Proline\",\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "df_wine = pd.read_csv(\"data/wine/wine.data\", header=None, names=COLUMN_NAMES)\n",
    "\n",
    "df_wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3df8bb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_wine.drop(\"Class\", axis=1).copy()\n",
    "y = df_wine[\"Class\"].copy()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "feature = scaler.fit_transform(np.array(X))\n",
    "target = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0e18ead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    feature, target, test_size=0.2, random_state=42, stratify=target\n",
    ")\n",
    "\n",
    "y_train = y_train - 1\n",
    "y_test = y_test - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e8259903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142, 13)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "471df3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        Input(shape=(13,)),\n",
    "        layers.Dense(32, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(3, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "878f2474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.1732 - loss: 1.2059 - val_accuracy: 0.3333 - val_loss: 1.1432\n",
      "Epoch 2/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1024 - loss: 1.1501 - val_accuracy: 0.2000 - val_loss: 1.1310\n",
      "Epoch 3/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2992 - loss: 1.1093 - val_accuracy: 0.2000 - val_loss: 1.1244\n",
      "Epoch 4/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4882 - loss: 1.0786 - val_accuracy: 0.2667 - val_loss: 1.1185\n",
      "Epoch 5/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5197 - loss: 1.0502 - val_accuracy: 0.3333 - val_loss: 1.1092\n",
      "Epoch 6/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5591 - loss: 1.0296 - val_accuracy: 0.3333 - val_loss: 1.0992\n",
      "Epoch 7/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5748 - loss: 1.0117 - val_accuracy: 0.3333 - val_loss: 1.0893\n",
      "Epoch 8/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5748 - loss: 0.9925 - val_accuracy: 0.3333 - val_loss: 1.0758\n",
      "Epoch 9/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6142 - loss: 0.9743 - val_accuracy: 0.3333 - val_loss: 1.0619\n",
      "Epoch 10/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6457 - loss: 0.9567 - val_accuracy: 0.3333 - val_loss: 1.0446\n",
      "Epoch 11/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6457 - loss: 0.9376 - val_accuracy: 0.3333 - val_loss: 1.0238\n",
      "Epoch 12/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6535 - loss: 0.9182 - val_accuracy: 0.3333 - val_loss: 1.0036\n",
      "Epoch 13/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6614 - loss: 0.8983 - val_accuracy: 0.3333 - val_loss: 0.9820\n",
      "Epoch 14/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6614 - loss: 0.8780 - val_accuracy: 0.3333 - val_loss: 0.9600\n",
      "Epoch 15/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6850 - loss: 0.8561 - val_accuracy: 0.4000 - val_loss: 0.9357\n",
      "Epoch 16/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7087 - loss: 0.8340 - val_accuracy: 0.6000 - val_loss: 0.9112\n",
      "Epoch 17/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7795 - loss: 0.8110 - val_accuracy: 0.6667 - val_loss: 0.8785\n",
      "Epoch 18/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8189 - loss: 0.7862 - val_accuracy: 0.6667 - val_loss: 0.8480\n",
      "Epoch 19/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8504 - loss: 0.7611 - val_accuracy: 0.8667 - val_loss: 0.8112\n",
      "Epoch 20/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8661 - loss: 0.7368 - val_accuracy: 0.9333 - val_loss: 0.7689\n",
      "Epoch 21/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8898 - loss: 0.7069 - val_accuracy: 0.9333 - val_loss: 0.7362\n",
      "Epoch 22/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9213 - loss: 0.6786 - val_accuracy: 0.9333 - val_loss: 0.7015\n",
      "Epoch 23/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9134 - loss: 0.6487 - val_accuracy: 0.9333 - val_loss: 0.6620\n",
      "Epoch 24/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9213 - loss: 0.6182 - val_accuracy: 1.0000 - val_loss: 0.6217\n",
      "Epoch 25/25\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9213 - loss: 0.5884 - val_accuracy: 1.0000 - val_loss: 0.5790\n"
     ]
    }
   ],
   "source": [
    "model_history = model.fit(X_train, y_train, epochs=25, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9c9b1861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - 29ms/step - accuracy: 0.8889 - loss: 0.5601\n",
      "Acurácia no teste: 0.8889\n"
     ]
    }
   ],
   "source": [
    "# Avaliar no teste\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Acurácia no teste: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1861b2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "y_pred_probs = model.predict(X_test)   # gera probabilidades\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)            # pega o dígito mais provável\n",
    "y_pred\n",
    "\n",
    "# Criar matriz de confusão\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_nomalize = confusion_matrix(y_test, y_pred, normalize=\"true\") * 100\n",
    "\n",
    "# Mostrar matriz\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=range(3))\n",
    "disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
    "plt.title(\"Matriz de Confusão - WINE\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e75278d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "rf_train = rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fd977f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_train.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a011c41",
   "metadata": {},
   "source": [
    "- Ambos os modelos tiveram bom desempenho, mas o Random Forest atingiu acurácia perfeita (1.0) nos dados de teste, enquanto a Rede Neural obteve 0.9722.\n",
    "- Aparentemente, em conjuntos de dados menores e mais simples, o Random Forest possui desempenho maior que a rede neural.\n",
    "\n",
    "> Com o treino usando 30 épocas temos também um modelo ideal com acurácia = 1.0 \n",
    "\n",
    "---\n",
    "\n",
    "#### EXERCÍCIO 2 – REGRESSÃO\n",
    "\n",
    "Dataset: California Housing Dataset (Scikit-learn)\n",
    "\n",
    "1. Treinar uma rede neural em Keras para prever o valor médio das casas.\n",
    "\n",
    "- Configuração mínima: 3 camadas ocultas com 64, 32 e 16 neurônios, função de ativação ReLU.\n",
    "- Camada de saída com 1 neurônio, função de ativação Linear.\n",
    "- Função de perda: mse.\n",
    "- Otimizador: Adam.\n",
    "\n",
    "2. Comparar os resultados com um modelo do scikit-learn (LinearRegression ou\n",
    "   RandomForestRegressor).\n",
    "3. Registrar métricas de erro (RMSE ou MAE) e discutir qual modelo teve melhor desempenho\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c2a2d803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8) (20640,)\n",
      "['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "print(housing.data.shape, housing.target.shape)\n",
    "print(housing.feature_names[0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "89cf8665",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_feature = scaler.fit_transform(housing.data)\n",
    "housing_target = housing.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b9d1bd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8)\n",
      "(20640,)\n"
     ]
    }
   ],
   "source": [
    "print(housing_feature.shape)\n",
    "print(housing_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "35264e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_housing_train, x_housing_test, y_housing_train, y_housing_test = train_test_split(\n",
    "    housing_feature,\n",
    "    housing_target,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4e316931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19032151, 0.62745098, 0.02957193, 0.01995318, 0.06437961,\n",
       "       0.00241382, 0.01806589, 0.72908367])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_housing_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2750cde7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.03)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_housing_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e2210436",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_model = keras.Sequential(\n",
    "    [\n",
    "        Input(shape=(8,)),\n",
    "        layers.Dense(64, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "        layers.Dense(32, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "        layers.Dense(16, activation=\"relu\"),\n",
    "        layers.Dense(1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "housing_model.compile(\n",
    "    optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b87e6e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4916 - mae: 0.4843 - val_loss: 0.5576 - val_mae: 0.4824\n",
      "Epoch 2/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4791 - mae: 0.4754 - val_loss: 0.5138 - val_mae: 0.4742\n",
      "Epoch 3/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4734 - mae: 0.4719 - val_loss: 0.5011 - val_mae: 0.4833\n",
      "Epoch 4/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4679 - mae: 0.4676 - val_loss: 0.4973 - val_mae: 0.4630\n",
      "Epoch 5/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4647 - mae: 0.4664 - val_loss: 0.5211 - val_mae: 0.5297\n",
      "Epoch 6/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4679 - mae: 0.4692 - val_loss: 0.4873 - val_mae: 0.4727\n",
      "Epoch 7/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4584 - mae: 0.4625 - val_loss: 0.4852 - val_mae: 0.4719\n",
      "Epoch 8/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4528 - mae: 0.4597 - val_loss: 0.4878 - val_mae: 0.4541\n",
      "Epoch 9/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4552 - mae: 0.4605 - val_loss: 0.4729 - val_mae: 0.4691\n",
      "Epoch 10/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.4506 - mae: 0.4586 - val_loss: 0.4716 - val_mae: 0.4696\n",
      "Epoch 11/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.4496 - mae: 0.4576 - val_loss: 0.4716 - val_mae: 0.4733\n",
      "Epoch 12/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4455 - mae: 0.4533 - val_loss: 0.4704 - val_mae: 0.4728\n",
      "Epoch 13/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4481 - mae: 0.4560 - val_loss: 0.4795 - val_mae: 0.4583\n",
      "Epoch 14/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4391 - mae: 0.4507 - val_loss: 0.4984 - val_mae: 0.5197\n",
      "Epoch 15/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.4392 - mae: 0.4498 - val_loss: 0.4623 - val_mae: 0.4450\n",
      "Epoch 16/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.4393 - mae: 0.4510 - val_loss: 0.4601 - val_mae: 0.4608\n",
      "Epoch 17/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4349 - mae: 0.4485 - val_loss: 0.4696 - val_mae: 0.4540\n",
      "Epoch 18/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.4301 - mae: 0.4464 - val_loss: 0.4573 - val_mae: 0.4758\n",
      "Epoch 19/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.4346 - mae: 0.4487 - val_loss: 0.4560 - val_mae: 0.4453\n",
      "Epoch 20/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.4304 - mae: 0.4461 - val_loss: 0.4457 - val_mae: 0.4435\n",
      "Epoch 21/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.4305 - mae: 0.4470 - val_loss: 0.4805 - val_mae: 0.4416\n",
      "Epoch 22/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.4313 - mae: 0.4461 - val_loss: 0.4520 - val_mae: 0.4680\n",
      "Epoch 23/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.4249 - mae: 0.4436 - val_loss: 0.4397 - val_mae: 0.4496\n",
      "Epoch 24/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4234 - mae: 0.4426 - val_loss: 0.4541 - val_mae: 0.4347\n",
      "Epoch 25/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4259 - mae: 0.4437 - val_loss: 0.4787 - val_mae: 0.5015\n",
      "Epoch 26/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4206 - mae: 0.4385 - val_loss: 0.4435 - val_mae: 0.4369\n",
      "Epoch 27/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4209 - mae: 0.4412 - val_loss: 0.4373 - val_mae: 0.4465\n",
      "Epoch 28/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4189 - mae: 0.4394 - val_loss: 0.4485 - val_mae: 0.4372\n",
      "Epoch 29/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4191 - mae: 0.4394 - val_loss: 0.4543 - val_mae: 0.4330\n",
      "Epoch 30/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4205 - mae: 0.4406 - val_loss: 0.4485 - val_mae: 0.4537\n",
      "Epoch 31/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4163 - mae: 0.4383 - val_loss: 0.4399 - val_mae: 0.4392\n",
      "Epoch 32/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4216 - mae: 0.4404 - val_loss: 0.4370 - val_mae: 0.4574\n",
      "Epoch 33/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4167 - mae: 0.4384 - val_loss: 0.4399 - val_mae: 0.4376\n",
      "Epoch 34/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4203 - mae: 0.4398 - val_loss: 0.5355 - val_mae: 0.5555\n",
      "Epoch 35/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4159 - mae: 0.4371 - val_loss: 0.4279 - val_mae: 0.4326\n",
      "Epoch 36/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4148 - mae: 0.4378 - val_loss: 0.4304 - val_mae: 0.4383\n",
      "Epoch 37/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4100 - mae: 0.4333 - val_loss: 0.5059 - val_mae: 0.5395\n",
      "Epoch 38/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4131 - mae: 0.4372 - val_loss: 0.4369 - val_mae: 0.4383\n",
      "Epoch 39/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4120 - mae: 0.4334 - val_loss: 0.4231 - val_mae: 0.4332\n",
      "Epoch 40/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4124 - mae: 0.4345 - val_loss: 0.4388 - val_mae: 0.4358\n",
      "Epoch 41/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4107 - mae: 0.4350 - val_loss: 0.4246 - val_mae: 0.4403\n",
      "Epoch 42/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4113 - mae: 0.4342 - val_loss: 0.4289 - val_mae: 0.4369\n",
      "Epoch 43/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4044 - mae: 0.4303 - val_loss: 0.4270 - val_mae: 0.4289\n",
      "Epoch 44/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4069 - mae: 0.4315 - val_loss: 0.4169 - val_mae: 0.4207\n",
      "Epoch 45/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4022 - mae: 0.4271 - val_loss: 0.4201 - val_mae: 0.4242\n",
      "Epoch 46/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4032 - mae: 0.4287 - val_loss: 0.4196 - val_mae: 0.4397\n",
      "Epoch 47/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4020 - mae: 0.4290 - val_loss: 0.4190 - val_mae: 0.4231\n",
      "Epoch 48/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3987 - mae: 0.4260 - val_loss: 0.4258 - val_mae: 0.4309\n",
      "Epoch 49/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3968 - mae: 0.4258 - val_loss: 0.4073 - val_mae: 0.4235\n",
      "Epoch 50/50\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3974 - mae: 0.4258 - val_loss: 0.4191 - val_mae: 0.4548\n"
     ]
    }
   ],
   "source": [
    "housing_history = housing_model.fit(x_housing_train, y_housing_train, epochs=50, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f8523fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Rede Neural - RMSE: 0.6322, MAE: 0.4512\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Previsões\n",
    "y_pred = housing_model.predict(x_housing_test)\n",
    "\n",
    "# Erros\n",
    "mse = mean_squared_error(y_housing_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_housing_test, y_pred)\n",
    "\n",
    "print(f\"Rede Neural - RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7bd3ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "ln_model = LinearRegression()\n",
    "\n",
    "ln_train = ln_model.fit(x_housing_train, y_housing_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e17e6876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5757877060324512"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln_train.score(x_housing_test, y_housing_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6ef5b432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressão linear - RMSE: 0.7456, MAE: 0.5332\n"
     ]
    }
   ],
   "source": [
    "# Previsões\n",
    "y_pred = ln_train.predict(x_housing_test)\n",
    "\n",
    "# Erros\n",
    "mse = mean_squared_error(y_housing_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_housing_test, y_pred)\n",
    "\n",
    "print(f\"Regressão linear - RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f67322",
   "metadata": {},
   "source": [
    "Ao se comparar uma Rede Neural com regressão linear utilizando o California Housing Dataset, percebemos que, a rede tem apresentado um desempenho ligeiramente melhor (RMSE: 0.63, MAE: 0.45) em relação à regressão linear (RMSE: 0.74, MAE: 0.53), nenhum dos dois modelos teve uma performance realmente satisfatória.\n",
    "\n",
    "Embora, as métricas sejam parecidas, RMSE e MSE, temos que para um bom modelos elas tem de se `aproximar de 0`. \n",
    "Outra métrica que temos é de R^2 = 0,5758 para a regressão linear, indicando que aquele modelo explica apenas metade da variação na variável\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
